
    bool TinyError::has_errors() const
    {
        // If this has an error, then return that there is one
        if (error_flag) 
            return true;

        // Search its dependencies for errors
        for (TinyError *dep : deps)
            if (dep->has_errors())
                return true;

        // Otherwise there is no errors to report
        return false;
    }

    void TinyError::report_errors(std::ostream &out)
    {
        for (TinyError *dep : deps)
            dep->report_errors(out);
    }

    Lexer::Lexer(std::istream &stream) :
        in(stream), eof_flag(false), index(0)
	{
        init();
	}

    Lexer::Lexer(string file_path) :
        in(file_in), eof_flag(false), index(0)
    {
        file_in = std::ifstream(file_path, std::ifstream::binary);
        if (!file_in.good())
        {
            // If the file could not be opened, trigger an error
            error("Could not open input file '" + file_path + "'");
            eof_flag = true;
            cache = nullptr;
            return;
        }

        init();
    }

    void Lexer::init()
    {
        cache = new char[128];
        next();
    }

    char Lexer::read_char(int index)
    {
        in.clear();
        in.seekg(index);
        return in.get();
    }

    char *Lexer::read_string(int index, int len)
    {
        in.clear();
        in.seekg(index);

        in.get(cache, len);
        cache[len] = '\0';
        return cache;
    }

    Lexer::MatchStatus Lexer::next_match(Token &token)
    {
        int types_left = STATE_COUNT;
        token.data = index;
        token.length = 0;

        // Reset state info
        memset(states, 0, STATE_COUNT * sizeof(int));
        memset(last_states, 0, STATE_COUNT * sizeof(int));

        // Read each char and check if it's a valid token, if not then stop checking
        // Repeat until all tokens are no longer valid
        while (types_left > 0 && !eof_flag)
        {
            // Read the next char
			char c = read_char(index++);
            token.length += 1;

            // Check to see if it marks the end of the file stream
            if (c == EOF)
            {
                eof_flag = true;
                break;
            }

            // Go through each token
            for (int i = 0; i < STATE_COUNT; i++)
            {
                // Only check still valid tokens
                if (states[i] != -1)
                {
                    // Find the next state
                    states[i] = type_table[i][states[i] * 128 + c];

                    // If the state is not valid, mark this
                    if (states[i] == -1)
                        types_left--;
                }
            }

            // If there's tokens left, copy update the last state data
            if (types_left > 0)
                memcpy(last_states, states, STATE_COUNT * sizeof(int));
        }

        // Find a valid token within the last valid state
        for (int i = 0; i < STATE_COUNT; i++)
        {
            if (last_states[i] != -1)
            {
                // Check to see if the state is within on of the end states
                for (int j = 0; j < type_end_state_count[i]; j++)
                {
                    if (type_end_states[i][j] == last_states[i])
                    {
                        // This is a valid token
                        index -= 1;
                        token.type = (Token::TokenType)i;
                        token.type_name = type_names[i];
                        return Lexer::MatchStatus::MATCH;
                    }
                }
            }
        }

        // If no types match
        return Lexer::MatchStatus::BLANK;
    }

    Token Lexer::next()
    {
        Token last = look;

        // Find the next valid token
        Lexer::MatchStatus status;
        do
        {
            status = next_match(look);
        } while (status != Lexer::MatchStatus::MATCH && !eof_flag);

        return last;
    }

    Token Lexer::match(Token::TokenType type, string name)
    {
        // Check token type info
        if (look.type != type)
        {
            error("Expected '" + name + "', got '" + 
                string("lolz") + "' instead", look);
        }

        // Get the next token
        return next();
    }

    void Lexer::error(string msg)
    {
        Error error;
        error.type = ErrorType::IOError;
        error.message = msg;
        errors.push_back(error);

        error_flag = true;
    }

    void Lexer::error(string msg, Token token)
    {
        Error error;
        error.type = ErrorType::ParseError;
        error.message = msg;
        error.index = token.data;
        errors.push_back(error);

        error_flag = true;
    }

    void Lexer::report_errors(std::ostream &out)
    {
        for (Error &error : errors)
        {
            out << "Error: " << error.message << std::endl;
        }
    }

    Lexer::~Lexer()
    {
        if (cache != nullptr)
            delete[] cache;
        file_in.close();
    }
