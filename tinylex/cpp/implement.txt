
    Lexer::Lexer(std::istream &stream) :
        in(stream), back_log('\0'), eof_flag(false) 
	{
		token.data = new char[80];
	}

    Lexer::Lexer(string file_path) :
        in(file_in), back_log('\0'), eof_flag(false)
    {
        file_in = std::ifstream(file_path);
		token.data = new char[80];
    }

    Lexer::MatchStatus Lexer::next_match(Token &token)
    {
        int buffer_pointer = 0;
        int types_left = STATE_COUNT;
        memset(states, 0, STATE_COUNT * sizeof(int));
        memset(last_states, 0, STATE_COUNT * sizeof(int));

		bool first_char = true;
        while (types_left > 0 && !eof_flag)
        {
			char c;
			if (back_log != '\0' && first_char)
				c = back_log;
			else
				c = in.get();

            if (c == EOF)
            {
                eof_flag = true;
                break;
            }

            for (int i = 0; i < STATE_COUNT; i++)
            {
                if (states[i] != -1)
                {
                    states[i] = type_table[i][states[i] * 128 + c];
                    if (states[i] == -1)
                        types_left--;
                }
            }

            token.data[buffer_pointer++] = c;
            if (types_left > 0)
                memcpy(last_states, states, STATE_COUNT * sizeof(int));
			first_char = false;
        }

        for (int i = 0; i < STATE_COUNT; i++)
        {
            if (last_states[i] != -1)
            {
                for (int j = 0; j < type_end_state_count[i]; j++)
                {
                    if (type_end_states[i][j] == last_states[i])
                    {
			            back_log = token.data[buffer_pointer - 1];
                        token.data[buffer_pointer - 1] = '\0';

                        token.type = (Token::TokenType)i;
                        token.type_name = type_names[i];
                        return Lexer::MatchStatus::MATCH;
                    }
                }
            }
        }

        // If no types match
		back_log = '\0';
        return Lexer::MatchStatus::BLANK;
    }

    const Token &Lexer::next()
    {
        Lexer::MatchStatus status;
        do
        {
            status = next_match(token);
        } while (status != Lexer::MatchStatus::MATCH && !eof_flag);

        return token;
    }

    Lexer::~Lexer()
    {
        delete token.data;
    }
